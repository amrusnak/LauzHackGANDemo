{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Dec  4 20:38:23 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.63.01    Driver Version: 470.63.01    CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  N/A |\r\n",
      "| N/A   44C    P0    30W /  N/A |    398MiB / 16125MiB |      4%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A       933      G   /usr/lib/xorg/Xorg                273MiB |\r\n",
      "|    0   N/A  N/A      1539      G   cinnamon                           67MiB |\r\n",
      "|    0   N/A  N/A      2031      G   /usr/lib/firefox/firefox           11MiB |\r\n",
      "|    0   N/A  N/A     14920      G   ...AAAAAAAAA= --shared-files       41MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torchvision as tv\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "import argparse\n",
    "import cv2\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, latent_dim=100, batchnorm=True):\n",
    "\n",
    "        #init\n",
    "        super(Generator, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.batchnorm = batchnorm\n",
    "        self._init_modules()\n",
    "\n",
    "    def _init_modules(self):\n",
    "\n",
    "        #project input\n",
    "\n",
    "        self.linear1 = nn.Linear(self.latent_dim, 256*40*40, bias=False)\n",
    "        self.bn1d1 = nn.BatchNorm1d(256*40*40) if self.batchnorm else None\n",
    "        self.leaky_relu = nn.LeakyReLU()\n",
    "\n",
    "        #convolutional layers\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=256, \n",
    "            out_channels=128, \n",
    "            kernel_size=5, \n",
    "            stride=1,\n",
    "            padding=2,\n",
    "            bias=False)\n",
    "\n",
    "        self.bn2d1 = nn.BatchNorm2d(128) if self.batchnorm else None\n",
    "\n",
    "        self.conv2 = nn.ConvTranspose2d(\n",
    "        in_channels=128, \n",
    "        out_channels=64, \n",
    "        kernel_size=4, \n",
    "        stride=2,\n",
    "        padding=1,\n",
    "        bias=False)\n",
    "\n",
    "        self.bn2d2 = nn.BatchNorm2d(64) if self.batchnorm else None\n",
    "\n",
    "        self.conv3 = nn.ConvTranspose2d(\n",
    "        in_channels=64, \n",
    "        out_channels=32, \n",
    "        kernel_size=4, \n",
    "        stride=2,\n",
    "        padding=1,\n",
    "        bias=False)\n",
    "\n",
    "        self.bn2d3 = nn.BatchNorm2d(32) if self.batchnorm else None\n",
    "\n",
    "        self.conv4 = nn.ConvTranspose2d(\n",
    "        in_channels=32, \n",
    "        out_channels=3, \n",
    "        kernel_size=4, \n",
    "        stride=2,\n",
    "        padding=1,\n",
    "        bias=False)\n",
    "\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "\n",
    "        #map latent vectors to samples\n",
    "        \n",
    "        intermediate = self.linear1(input_tensor)\n",
    "        intermediate = self.bn1d1(intermediate)\n",
    "        intermediate = self.leaky_relu(intermediate)\n",
    "\n",
    "        intermediate = intermediate.view((-1, 256, 40, 40))\n",
    "\n",
    "        intermediate = self.conv1(intermediate)\n",
    "        if self.batchnorm:\n",
    "            intermediate = self.bn2d1(intermediate)\n",
    "        intermediate = self.leaky_relu(intermediate)\n",
    "\n",
    "        intermediate = self.conv2(intermediate)\n",
    "        if self.batchnorm:\n",
    "            intermediate = self.bn2d2(intermediate)\n",
    "        intermediate = self.leaky_relu(intermediate)\n",
    "\n",
    "        intermediate = self.conv3(intermediate)\n",
    "        if self.batchnorm:\n",
    "            intermediate = self.bn2d3(intermediate)\n",
    "        intermediate = self.leaky_relu(intermediate)\n",
    "\n",
    "        intermediate = self.conv4(intermediate)\n",
    "        \n",
    "        output_tensor = self.tanh(intermediate)\n",
    "\n",
    "        return output_tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(Discriminator, self).__init__()\n",
    "\t\tself._init_modules()\n",
    "\n",
    "\tdef _init_modules(self):\n",
    "\n",
    "\t\tself.conv1 = nn.Conv2d(\n",
    "\t\t\t\tin_channels=3,\n",
    "\t\t\t\tout_channels=64,\n",
    "\t\t\t\tkernel_size=5,\n",
    "\t\t\t\tstride=2,\n",
    "\t\t\t\tpadding=2,\n",
    "\t\t\t\tbias=True)\n",
    "\n",
    "\t\tself.leaky_relu = nn.LeakyReLU()\n",
    "\t\tself.dropout_2d = nn.Dropout2d(0.3)\n",
    "\n",
    "\t\tself.conv2 = nn.Conv2d(\n",
    "\t\t\tin_channels=64,\n",
    "\t\t\tout_channels=128,\n",
    "\t\t\tkernel_size=5,\n",
    "\t\t\tstride=2,\n",
    "\t\t\tpadding=2,\n",
    "\t\t\tbias=True)\n",
    "\n",
    "\t\tself.linear1 = nn.Linear(128*40*40, 1, bias=True)\n",
    "\t\tself.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\tdef forward(self, input_tensor):\n",
    "\n",
    "\t\tintermediate = self.conv1(input_tensor)\n",
    "\t\tintermediate = self.leaky_relu(intermediate)\n",
    "\t\tintermediate = self.dropout_2d(intermediate)\n",
    "\n",
    "\t\tintermediate = self.conv2(intermediate)\n",
    "\t\tintermediate = self.leaky_relu(intermediate)\n",
    "\t\tintermediate = self.dropout_2d(intermediate)\n",
    "\t\t\n",
    "\t\tintermediate = intermediate.view((-1, 128*40*40))\n",
    "\t\tintermediate = self.linear1(intermediate)\n",
    "\t\toutput_tensor = self.sigmoid(intermediate)\n",
    "\n",
    "\t\treturn output_tensor\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
